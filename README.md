MULTI-AGENT REINFORCEMENT LEARNING (PPO - Proximal Policy Optimization) WITH TORCHRL TUTORIAL

Key learnings:

- How to create a multi-agent environment in TorchRL, how its specs work, and how it integrates with the library;

- How you use GPU vectorized environments in TorchRL;

- How to create different multi-agent network architectures in TorchRL (e.g., using parameter sharing, centralised critic)

- How we can use tensordict.TensorDict to carry multi-agent data;

- How we can tie all the library components (collectors, modules, replay buffers, and losses) in a multi-agent MAPPO/IPPO training loop.

![Multi-agent Navigation scenario]((https://pytorch.s3.amazonaws.com/torchrl/github-artifacts/img/navigation.gif))
